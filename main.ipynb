{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a3a9ec",
   "metadata": {},
   "source": [
    "# Carregamento da Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed01c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ucimlrepo in /home/alef/.local/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/alef/.local/lib/python3.10/site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /home/alef/.local/lib/python3.10/site-packages (from ucimlrepo) (2025.11.12)\n",
      "Requirement already satisfied: ucimlrepo in /home/alef/.local/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/alef/.local/lib/python3.10/site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /home/alef/.local/lib/python3.10/site-packages (from ucimlrepo) (2025.11.12)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.2.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.0.0->ucimlrepo) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.2.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.0.0->ucimlrepo) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed1b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "statlog_german_credit_data = fetch_ucirepo(id=144) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_german_credit_data.data.features \n",
    "y = statlog_german_credit_data.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada4383",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c701c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alef/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Reamostragem (classes desbalanceadas)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Validação e busca de hiperparâmetros\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    ")\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "# Otimizadores\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real as SKOReal, Integer as SKOInteger, Categorical as SKOCategorical\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Continuous as GAContinuous, Integer as GAInteger, Categorical as GACategorical\n",
    "from scipy import sparse\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Utilidades\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af70e8",
   "metadata": {},
   "source": [
    "# Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423cf620",
   "metadata": {},
   "source": [
    "## Juntar as features e o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9117e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X, y], axis=1)\n",
    "data.columns = list(X.columns) + ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4bc3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Attribute1   1000 non-null   object\n",
      " 1   Attribute2   1000 non-null   int64 \n",
      " 2   Attribute3   1000 non-null   object\n",
      " 3   Attribute4   1000 non-null   object\n",
      " 4   Attribute5   1000 non-null   int64 \n",
      " 5   Attribute6   1000 non-null   object\n",
      " 6   Attribute7   1000 non-null   object\n",
      " 7   Attribute8   1000 non-null   int64 \n",
      " 8   Attribute9   1000 non-null   object\n",
      " 9   Attribute10  1000 non-null   object\n",
      " 10  Attribute11  1000 non-null   int64 \n",
      " 11  Attribute12  1000 non-null   object\n",
      " 12  Attribute13  1000 non-null   int64 \n",
      " 13  Attribute14  1000 non-null   object\n",
      " 14  Attribute15  1000 non-null   object\n",
      " 15  Attribute16  1000 non-null   int64 \n",
      " 16  Attribute17  1000 non-null   object\n",
      " 17  Attribute18  1000 non-null   int64 \n",
      " 18  Attribute19  1000 non-null   object\n",
      " 19  Attribute20  1000 non-null   object\n",
      " 20  target       1000 non-null   int64 \n",
      "dtypes: int64(8), object(13)\n",
      "memory usage: 164.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1ac8f",
   "metadata": {},
   "source": [
    "## Remoção de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f36db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute11</th>\n",
       "      <th>Attribute13</th>\n",
       "      <th>Attribute16</th>\n",
       "      <th>Attribute18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.307000</td>\n",
       "      <td>3051.101000</td>\n",
       "      <td>2.973000</td>\n",
       "      <td>2.845000</td>\n",
       "      <td>35.453500</td>\n",
       "      <td>1.404000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.615151</td>\n",
       "      <td>2187.140403</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>11.106324</td>\n",
       "      <td>0.565335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2319.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3972.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>7882.375000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Attribute2   Attribute5   Attribute8  Attribute11  Attribute13  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     20.307000  3051.101000     2.973000     2.845000    35.453500   \n",
       "std      10.615151  2187.140403     1.118715     1.103718    11.106324   \n",
       "min       4.000000   250.000000     1.000000     1.000000    19.000000   \n",
       "25%      12.000000  1365.500000     2.000000     2.000000    27.000000   \n",
       "50%      18.000000  2319.500000     3.000000     3.000000    33.000000   \n",
       "75%      24.000000  3972.250000     4.000000     4.000000    42.000000   \n",
       "max      42.000000  7882.375000     4.000000     4.000000    64.500000   \n",
       "\n",
       "       Attribute16  Attribute18  \n",
       "count  1000.000000       1000.0  \n",
       "mean      1.404000          1.0  \n",
       "std       0.565335          0.0  \n",
       "min       1.000000          1.0  \n",
       "25%       1.000000          1.0  \n",
       "50%       1.000000          1.0  \n",
       "75%       2.000000          1.0  \n",
       "max       3.500000          1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != 'target']\n",
    "\n",
    "# IQR capping  \n",
    "def iqr_cap(series, factor=1.5):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - factor * iqr\n",
    "    upper = q3 + factor * iqr\n",
    "    return series.clip(lower, upper)\n",
    "\n",
    "# Aplicar capping aos numéricos\n",
    "for col in numeric_cols:\n",
    "    data[col] = iqr_cap(data[col])\n",
    "\n",
    "data[numeric_cols].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1c06c",
   "metadata": {},
   "source": [
    "## Separação Entre Features e Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa447c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75082fd",
   "metadata": {},
   "source": [
    "## Separar Features Numericas e Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "980c00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X.select_dtypes(include=np.number).columns\n",
    "categorical_features = X.select_dtypes(exclude=np.number).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b62db",
   "metadata": {},
   "source": [
    "## Pipeline de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2471f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numéricas: imputar valores ausentes com a mediana e escalar\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# categóricas: imputar valores ausentes com o valor mais frequente e aplicar One-Hot Encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f5ada",
   "metadata": {},
   "source": [
    "## Processador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b78889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um pré-processador usando ColumnTransformer para aplicar transformações diferentes a diferentes colunas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # Manter outras colunas não especificadas, se houver\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05163c5a",
   "metadata": {},
   "source": [
    "### Aplicando as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ddbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876ff3b",
   "metadata": {},
   "source": [
    "## Convertendo Rótulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24017660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original usa 1 = Good, 2 = Bad. Converter 2 para 0 para ter classes 0 e 1.\n",
    "y_processed = y.values.ravel()\n",
    "y_processed = np.where(y_processed == 2, 0, y_processed) # 1 (Good credit), 0 (Bad credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7cd1f",
   "metadata": {},
   "source": [
    "## Split Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a6feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_processed, test_size=0.2, random_state=RANDOM_STATE, stratify=y_processed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7fe6d",
   "metadata": {},
   "source": [
    "## Dados Sinteticos (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a954119",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e350efa",
   "metadata": {},
   "source": [
    "# Cenários de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aded5e4",
   "metadata": {},
   "source": [
    "## Função para Garatir Densidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce06c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para algoritmos que exigem matriz densa\n",
    "def to_dense(X):\n",
    "    return X.toarray() if sparse.issparse(X) else X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1069d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled = X_resampled  # resultado do SMOTE\n",
    "X_test_original = X_test         # teste sem oversampling\n",
    "\n",
    "X_train_resampled_dense = to_dense(X_train_resampled)\n",
    "X_test_dense = to_dense(X_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560da56b",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fa3f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3, random_state=RANDOM_STATE)\n",
    "X_train_pca = pca.fit_transform(X_train_resampled_dense)\n",
    "X_test_pca = pca.transform(X_test_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20241a2c",
   "metadata": {},
   "source": [
    "## Divisão de Cenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74af0768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': (1120, 61), 'pca_3': (1120, 3)}\n"
     ]
    }
   ],
   "source": [
    "# Dicionário de cenários de classificação\n",
    "classification_scenarios = {\n",
    "    'normal': (X_train_resampled_dense, X_test_dense),\n",
    "    'pca_3': (X_train_pca, X_test_pca)\n",
    "}\n",
    "print({name: train.shape for name, (train, _) in classification_scenarios.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da369376",
   "metadata": {},
   "source": [
    "# Espaços de Hiperparâmetros (Grid, Random, Bayes, Genética)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694dbd47",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d648730",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f38b8",
   "metadata": {},
   "source": [
    "## Estimadores base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f23f7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimadores base (modelos)\n",
    "base_estimators = {\n",
    "    'rf': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'svm': SVC(probability=True, random_state=RANDOM_STATE),\n",
    "    'mlp': MLPClassifier(max_iter=400, solver='adam', early_stopping=True, random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422b2e0",
   "metadata": {},
   "source": [
    "## Grid (compacto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d81226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'rf': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': [5, 11, 17],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': [0.5, 1, 5],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (150,)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [1e-5, 1e-4, 1e-3]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea74c37",
   "metadata": {},
   "source": [
    "## Random distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5c970af",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params = {\n",
    "    'rf': {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': [None] + list(range(5, 16, 5)),\n",
    "        'min_samples_split': randint(2, 10)\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': randint(3, 25),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': randint(1, 3)\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': uniform(0.1, 10),\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (150,)],\n",
    "        'activation': ['relu', 'tanh', 'logistic'],\n",
    "        'alpha': uniform(1e-6, 1e-2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc19b13",
   "metadata": {},
   "source": [
    "## Bayes search spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c1a6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_params = {\n",
    "    'rf': {\n",
    "        'n_estimators': SKOInteger(50, 300),\n",
    "        'max_depth': SKOCategorical([None, 5, 10, 15]),\n",
    "        'min_samples_split': SKOInteger(2, 10)\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': SKOInteger(3, 25),\n",
    "        'weights': SKOCategorical(['uniform', 'distance']),\n",
    "        'p': SKOInteger(1, 2)\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': SKOReal(0.1, 10.0, prior='log-uniform'),\n",
    "        'gamma': SKOCategorical(['scale', 'auto']),\n",
    "        'kernel': SKOCategorical(['rbf', 'linear'])\n",
    "    },\n",
    "    'mlp': {\n",
    "        'activation': SKOCategorical(['relu', 'tanh', 'logistic']),\n",
    "        'alpha': SKOReal(1e-6, 1e-2, prior='log-uniform')\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8cb631",
   "metadata": {},
   "source": [
    "## GA search spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "881f4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_params = {\n",
    "    'rf': {\n",
    "        'n_estimators': GAInteger(50, 300),\n",
    "        'max_depth': GACategorical([None, 5, 10, 15]),\n",
    "        'min_samples_split': GAInteger(2, 10)\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': GAInteger(3, 25),\n",
    "        'weights': GACategorical(['uniform', 'distance']),\n",
    "        'p': GAInteger(1, 2)\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': GAContinuous(0.1, 10.0),\n",
    "        'gamma': GACategorical(['scale', 'auto']),\n",
    "        'kernel': GACategorical(['rbf', 'linear'])\n",
    "    },\n",
    "    'mlp': {\n",
    "        'activation': GACategorical(['relu', 'tanh', 'logistic']),\n",
    "        'alpha': GAContinuous(1e-6, 1e-2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8597a00",
   "metadata": {},
   "source": [
    "# Otimização e Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f59c2d",
   "metadata": {},
   "source": [
    "## Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66cd2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'kappa': make_scorer(cohen_kappa_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d1bcc",
   "metadata": {},
   "source": [
    "## Função fit search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b86ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_search(search_obj, X, y):\n",
    "    \"\"\"\n",
    "    Para medir o tempo de execução do fit em \n",
    "    buscas de hiperparâmetros\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    search_obj.fit(X, y)\n",
    "    return search_obj, time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96cc65",
   "metadata": {},
   "source": [
    "## Função de Criação do Otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43a51b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search(algorithm_key: str, optimizer_type: str):\n",
    "    \"\"\"\n",
    "    Retorna um objeto de busca de hiperparâmetros configurado para o algoritmo\n",
    "    e o otimizador especificados.\n",
    "    \"\"\"\n",
    "    estimator = base_estimators[algorithm_key]\n",
    "    scoring_metric = 'f1'\n",
    "\n",
    "    if optimizer_type == 'grid':\n",
    "        return GridSearchCV(\n",
    "            estimator=estimator,\n",
    "            param_grid=grid_params[algorithm_key],\n",
    "            cv=cv,\n",
    "            scoring=scoring_metric,\n",
    "            n_jobs=-1,\n",
    "            refit=True\n",
    "        )\n",
    "\n",
    "    if optimizer_type == 'random':\n",
    "        return RandomizedSearchCV(\n",
    "            estimator=estimator,\n",
    "            param_distributions=random_params[algorithm_key],\n",
    "            n_iter=15,\n",
    "            cv=cv,\n",
    "            scoring=scoring_metric,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1,\n",
    "            refit=True\n",
    "        )\n",
    "\n",
    "    if optimizer_type == 'bayes':\n",
    "        return BayesSearchCV(\n",
    "            estimator=estimator,\n",
    "            search_spaces=bayes_params[algorithm_key],\n",
    "            n_iter=20,\n",
    "            cv=cv,\n",
    "            scoring=scoring_metric,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1,\n",
    "            refit=True\n",
    "        )\n",
    "\n",
    "    if optimizer_type == 'genetic':\n",
    "        return GASearchCV(\n",
    "            estimator=estimator,\n",
    "            param_grid=ga_params[algorithm_key],\n",
    "            cv=cv,\n",
    "            scoring=scoring_metric,\n",
    "            population_size=12,\n",
    "            generations=8,\n",
    "            tournament_size=3,\n",
    "            n_jobs=-1,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "    raise ValueError(f\"Tipo de busca inválido: {optimizer_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb4572",
   "metadata": {},
   "source": [
    "## Função para Avaliar um Estimador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74df8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best(best_estimator, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Avalia um estimador: calcula médias/desvios das métricas via CV e métricas no conjunto de teste.\n",
    "    Retorna um dicionário com chaves:\n",
    "      - {metric}_cv_mean, {metric}_cv_std  (accuracy, precision, recall, f1, roc_auc, kappa)\n",
    "      - {metric}_test (accuracy_test, precision_test, recall_test, f1_test, roc_auc_test, kappa_test)\n",
    "    \"\"\"\n",
    "    metrics_list = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'kappa']\n",
    "\n",
    "    def _cv_summary(est, X, y):\n",
    "        cv_results = cross_validate(est, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "        mean_dict = {f'{m}_cv_mean': np.mean(cv_results[f'test_{m}']) for m in metrics_list}\n",
    "        std_dict = {f'{m}_cv_std': np.std(cv_results[f'test_{m}']) for m in metrics_list}\n",
    "        return {**mean_dict, **std_dict}\n",
    "\n",
    "    def _get_proba(est, X):\n",
    "        # retorna probabilidade positiva (ou aproximação)\n",
    "        if hasattr(est, 'predict_proba'):\n",
    "            return est.predict_proba(X)[:, 1]\n",
    "        if hasattr(est, 'decision_function'):\n",
    "            dec = est.decision_function(X).reshape(-1, 1)\n",
    "            return MinMaxScaler().fit_transform(dec).ravel()\n",
    "        # fallback: usar predições (binário 0/1) como \"probabilidade\" aproximada\n",
    "        return est.predict(X)\n",
    "\n",
    "    def _test_metrics(est, X, y_true):\n",
    "        y_pred = est.predict(X)\n",
    "        y_proba = _get_proba(est, X)\n",
    "        # roc_auc pode falhar se houver apenas uma classe nas predições/probabilidades\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_true, y_proba)\n",
    "        except Exception:\n",
    "            roc_auc = np.nan\n",
    "        return {\n",
    "            'accuracy_test': accuracy_score(y_true, y_pred),\n",
    "            'precision_test': precision_score(y_true, y_pred),\n",
    "            'recall_test': recall_score(y_true, y_pred),\n",
    "            'f1_test': f1_score(y_true, y_pred),\n",
    "            'roc_auc_test': roc_auc,\n",
    "            'kappa_test': cohen_kappa_score(y_true, y_pred)\n",
    "        }\n",
    "\n",
    "    cv_summary = _cv_summary(best_estimator, X_train, y_train)\n",
    "    test_summary = _test_metrics(best_estimator, X_test, y_test)\n",
    "    return {**cv_summary, **test_summary}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daf6716",
   "metadata": {},
   "source": [
    "# Execução dos Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd5832ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_records = []\n",
    "best_result_per_scenario = {}\n",
    "\n",
    "optimizer_list = ['grid', 'random', 'bayes', 'genetic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77369281",
   "metadata": {},
   "source": [
    "## Loop Principal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a5534f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cenário: normal ===\n",
      " - RF via grid ... OK\n",
      " - RF via random ... OK\n",
      " - RF via random ... OK\n",
      " - RF via bayes ... OK\n",
      " - RF via bayes ... OK\n",
      " - RF via genetic ... OK\n",
      " - RF via genetic ... OK\n",
      " - KNN via grid ... OK\n",
      " - KNN via random ... OK\n",
      " - KNN via grid ... OK\n",
      " - KNN via random ... OK\n",
      " - KNN via bayes ... OK\n",
      " - KNN via bayes ... OK\n",
      " - KNN via genetic ... OK\n",
      " - KNN via genetic ... OK\n",
      " - SVM via grid ... OK\n",
      " - SVM via grid ... OK\n",
      " - SVM via random ... OK\n",
      " - SVM via random ... OK\n",
      " - SVM via bayes ... OK\n",
      " - SVM via bayes ... OK\n",
      " - SVM via genetic ... OK\n",
      " - SVM via genetic ... OK\n",
      " - MLP via grid ... OK\n",
      " - MLP via grid ... OK\n",
      " - MLP via random ... OK\n",
      " - MLP via random ... OK\n",
      " - MLP via bayes ... OK\n",
      " - MLP via bayes ... OK\n",
      " - MLP via genetic ... OK\n",
      " - MLP via genetic ... OK\n",
      "-> Melhor: RF + random | f1_test=0.8235 | tempo_cenário=287.6s\n",
      "\n",
      "=== Cenário: pca_3 ===\n",
      " - RF via grid ... OK\n",
      "-> Melhor: RF + random | f1_test=0.8235 | tempo_cenário=287.6s\n",
      "\n",
      "=== Cenário: pca_3 ===\n",
      " - RF via grid ... OK\n",
      " - RF via random ... OK\n",
      " - RF via random ... OK\n",
      " - RF via bayes ... OK\n",
      " - RF via bayes ... OK\n",
      " - RF via genetic ... OK\n",
      " - RF via genetic ... OK\n",
      " - KNN via grid ... OK\n",
      " - KNN via random ... OK\n",
      " - KNN via grid ... OK\n",
      " - KNN via random ... OK\n",
      " - KNN via bayes ... OK\n",
      " - KNN via bayes ... OK\n",
      " - KNN via genetic ... OK\n",
      " - KNN via genetic ... OK\n",
      " - SVM via grid ... OK\n",
      " - SVM via grid ... OK\n",
      " - SVM via random ... OK\n",
      " - SVM via random ... OK\n",
      " - SVM via bayes ... OK\n",
      " - SVM via bayes ... OK\n",
      " - SVM via genetic ... OK\n",
      " - SVM via genetic ... OK\n",
      " - MLP via grid ... OK\n",
      " - MLP via grid ... OK\n",
      " - MLP via random ... OK\n",
      " - MLP via random ... OK\n",
      " - MLP via bayes ... OK\n",
      " - MLP via bayes ... OK\n",
      " - MLP via genetic ... OK\n",
      " - MLP via genetic ... OK\n",
      "-> Melhor: RF + grid | f1_test=0.7730 | tempo_cenário=237.7s\n",
      "OK\n",
      "-> Melhor: RF + grid | f1_test=0.7730 | tempo_cenário=237.7s\n"
     ]
    }
   ],
   "source": [
    "def _execute_search(algorithm_key, optimizer_type, X_train_scenario, y_train_scenario, X_test_scenario, y_test_scenario):\n",
    "    \"\"\"\n",
    "    Constrói, ajusta e avalia uma busca. Retorna (record, None) em sucesso ou (None, error_message) em falha.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        search_obj = build_search(algorithm_key, optimizer_type)\n",
    "        fitted_search, elapsed_seconds = fit_search(search_obj, X_train_scenario, y_train_scenario)\n",
    "        best_estimator = fitted_search.best_estimator_\n",
    "        metrics = evaluate_best(best_estimator, X_train_scenario, y_train_scenario, X_test_scenario, y_test_scenario)\n",
    "\n",
    "        record = {\n",
    "            'scenario': None,  # preenchido pelo chamador\n",
    "            'algorithm': algorithm_key,\n",
    "            'optimizer': optimizer_type,\n",
    "            'time_sec': elapsed_seconds,\n",
    "            'best_params': fitted_search.best_params_,\n",
    "        }\n",
    "        record.update(metrics)\n",
    "        return record, None\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "\n",
    "for scenario_name, (X_train_scenario, X_test_scenario) in classification_scenarios.items():\n",
    "    print(f\"\\n=== Cenário: {scenario_name} ===\")\n",
    "    y_train_scenario = y_resampled\n",
    "    y_test_scenario = y_test\n",
    "\n",
    "    scenario_start = time.time()\n",
    "    scenario_records = []\n",
    "    failures = []\n",
    "\n",
    "    for algorithm_key in base_estimators.keys():\n",
    "        for optimizer_type in optimizer_list:\n",
    "            print(f\" - {algorithm_key.upper()} via {optimizer_type} ...\", end=' ')\n",
    "            record, error = _execute_search(\n",
    "                algorithm_key,\n",
    "                optimizer_type,\n",
    "                X_train_scenario,\n",
    "                y_train_scenario,\n",
    "                X_test_scenario,\n",
    "                y_test_scenario\n",
    "            )\n",
    "            if record is not None:\n",
    "                record['scenario'] = scenario_name\n",
    "                experiment_records.append(record)\n",
    "                scenario_records.append(record)\n",
    "                print(\"OK\")\n",
    "            else:\n",
    "                failures.append({\n",
    "                    'scenario': scenario_name,\n",
    "                    'algorithm': algorithm_key,\n",
    "                    'optimizer': optimizer_type,\n",
    "                    'error': error\n",
    "                })\n",
    "                print(f\"Falhou ({error})\")\n",
    "\n",
    "    scenario_elapsed = time.time() - scenario_start\n",
    "\n",
    "    # Selecionar melhor por F1 em teste neste cenário\n",
    "    if scenario_records:\n",
    "        scenario_df = pd.DataFrame(scenario_records)\n",
    "        top_row = scenario_df.sort_values('f1_test', ascending=False).iloc[0]\n",
    "\n",
    "        best_result_per_scenario[scenario_name] = {\n",
    "            'algorithm': top_row['algorithm'],\n",
    "            'optimizer': top_row['optimizer'],\n",
    "            'f1_test': top_row['f1_test'],\n",
    "            'roc_auc_test': top_row['roc_auc_test'],\n",
    "            'best_params': top_row['best_params'],\n",
    "            'n_runs': len(scenario_records),\n",
    "            'n_failures': len(failures),\n",
    "            'failures': failures\n",
    "        }\n",
    "\n",
    "        print(f\"-> Melhor: {top_row['algorithm'].upper()} + {top_row['optimizer']} | f1_test={top_row['f1_test']:.4f} | tempo_cenário={scenario_elapsed:.1f}s\")\n",
    "    else:\n",
    "        best_result_per_scenario[scenario_name] = {\n",
    "            'algorithm': None,\n",
    "            'optimizer': None,\n",
    "            'f1_test': None,\n",
    "            'roc_auc_test': None,\n",
    "            'best_params': None,\n",
    "            'n_runs': 0,\n",
    "            'n_failures': len(failures),\n",
    "            'failures': failures\n",
    "        }\n",
    "        print(f\"-> Nenhum experimento bem-sucedido neste cenário (tempo_cenário={scenario_elapsed:.1f}s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ffe5f",
   "metadata": {},
   "source": [
    "## Consolidar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c7661ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo (top 10 por F1 em teste):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>best_params</th>\n",
       "      <th>accuracy_cv_mean</th>\n",
       "      <th>precision_cv_mean</th>\n",
       "      <th>recall_cv_mean</th>\n",
       "      <th>f1_cv_mean</th>\n",
       "      <th>roc_auc_cv_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_cv_std</th>\n",
       "      <th>f1_cv_std</th>\n",
       "      <th>roc_auc_cv_std</th>\n",
       "      <th>kappa_cv_std</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>roc_auc_test</th>\n",
       "      <th>kappa_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>rf</td>\n",
       "      <td>random</td>\n",
       "      <td>10.931897</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.849107</td>\n",
       "      <td>0.834394</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.852226</td>\n",
       "      <td>0.925446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031237</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.009301</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.798658</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.365672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>rf</td>\n",
       "      <td>grid</td>\n",
       "      <td>6.254917</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.837010</td>\n",
       "      <td>0.860714</td>\n",
       "      <td>0.848255</td>\n",
       "      <td>0.922816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036857</td>\n",
       "      <td>0.018545</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.032242</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.787262</td>\n",
       "      <td>0.392523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>rf</td>\n",
       "      <td>bayes</td>\n",
       "      <td>25.663683</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 3, 'n_e...</td>\n",
       "      <td>0.851786</td>\n",
       "      <td>0.834242</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.855536</td>\n",
       "      <td>0.927583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.025505</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.785119</td>\n",
       "      <td>0.329268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>rf</td>\n",
       "      <td>genetic</td>\n",
       "      <td>90.193166</td>\n",
       "      <td>{'n_estimators': 276, 'max_depth': None, 'min_...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.838973</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.860705</td>\n",
       "      <td>0.928045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025877</td>\n",
       "      <td>0.014522</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>0.026486</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.783571</td>\n",
       "      <td>0.306931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>normal</td>\n",
       "      <td>svm</td>\n",
       "      <td>bayes</td>\n",
       "      <td>15.727480</td>\n",
       "      <td>{'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.896727</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.852024</td>\n",
       "      <td>0.941486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024614</td>\n",
       "      <td>0.014120</td>\n",
       "      <td>0.014539</td>\n",
       "      <td>0.026845</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.798587</td>\n",
       "      <td>0.722857</td>\n",
       "      <td>0.311594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>normal</td>\n",
       "      <td>svm</td>\n",
       "      <td>genetic</td>\n",
       "      <td>58.652644</td>\n",
       "      <td>{'C': 9.317198553940596, 'gamma': 'scale', 'ke...</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.895253</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.852308</td>\n",
       "      <td>0.940976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.014631</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.798587</td>\n",
       "      <td>0.725119</td>\n",
       "      <td>0.311594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>normal</td>\n",
       "      <td>mlp</td>\n",
       "      <td>bayes</td>\n",
       "      <td>10.633513</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001867755735...</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.766185</td>\n",
       "      <td>0.717857</td>\n",
       "      <td>0.738326</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094929</td>\n",
       "      <td>0.067031</td>\n",
       "      <td>0.038358</td>\n",
       "      <td>0.118934</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.774762</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>normal</td>\n",
       "      <td>svm</td>\n",
       "      <td>grid</td>\n",
       "      <td>5.139695</td>\n",
       "      <td>{'C': 5, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.886675</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.850428</td>\n",
       "      <td>0.935029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.784173</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.292453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normal</td>\n",
       "      <td>svm</td>\n",
       "      <td>random</td>\n",
       "      <td>7.649476</td>\n",
       "      <td>{'C': 4.419450186421157, 'gamma': 'scale', 'ke...</td>\n",
       "      <td>0.855357</td>\n",
       "      <td>0.881994</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.850153</td>\n",
       "      <td>0.933530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029342</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>0.013851</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.780142</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.744405</td>\n",
       "      <td>0.270335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>normal</td>\n",
       "      <td>mlp</td>\n",
       "      <td>genetic</td>\n",
       "      <td>28.702915</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.005083389385...</td>\n",
       "      <td>0.749107</td>\n",
       "      <td>0.766541</td>\n",
       "      <td>0.719643</td>\n",
       "      <td>0.739608</td>\n",
       "      <td>0.820233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093576</td>\n",
       "      <td>0.066939</td>\n",
       "      <td>0.038342</td>\n",
       "      <td>0.119443</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.721429</td>\n",
       "      <td>0.779923</td>\n",
       "      <td>0.777738</td>\n",
       "      <td>0.383117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scenario algorithm optimizer   time_sec  \\\n",
       "1    normal        rf    random  10.931897   \n",
       "0    normal        rf      grid   6.254917   \n",
       "2    normal        rf     bayes  25.663683   \n",
       "3    normal        rf   genetic  90.193166   \n",
       "10   normal       svm     bayes  15.727480   \n",
       "11   normal       svm   genetic  58.652644   \n",
       "14   normal       mlp     bayes  10.633513   \n",
       "8    normal       svm      grid   5.139695   \n",
       "9    normal       svm    random   7.649476   \n",
       "15   normal       mlp   genetic  28.702915   \n",
       "\n",
       "                                          best_params  accuracy_cv_mean  \\\n",
       "1   {'max_depth': 15, 'min_samples_split': 5, 'n_e...          0.849107   \n",
       "0   {'max_depth': 10, 'min_samples_split': 2, 'n_e...          0.846429   \n",
       "2   {'max_depth': 15, 'min_samples_split': 3, 'n_e...          0.851786   \n",
       "3   {'n_estimators': 276, 'max_depth': None, 'min_...          0.857143   \n",
       "10     {'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}          0.858929   \n",
       "11  {'C': 9.317198553940596, 'gamma': 'scale', 'ke...          0.858929   \n",
       "14  {'activation': 'relu', 'alpha': 0.001867755735...          0.748214   \n",
       "8         {'C': 5, 'gamma': 'scale', 'kernel': 'rbf'}          0.856250   \n",
       "9   {'C': 4.419450186421157, 'gamma': 'scale', 'ke...          0.855357   \n",
       "15  {'activation': 'relu', 'alpha': 0.005083389385...          0.749107   \n",
       "\n",
       "    precision_cv_mean  recall_cv_mean  f1_cv_mean  roc_auc_cv_mean  ...  \\\n",
       "1            0.834394        0.871429    0.852226         0.925446  ...   \n",
       "0            0.837010        0.860714    0.848255         0.922816  ...   \n",
       "2            0.834242        0.878571    0.855536         0.927583  ...   \n",
       "3            0.838973        0.883929    0.860705         0.928045  ...   \n",
       "10           0.896727        0.812500    0.852024         0.941486  ...   \n",
       "11           0.895253        0.814286    0.852308         0.940976  ...   \n",
       "14           0.766185        0.717857    0.738326         0.820408  ...   \n",
       "8            0.886675        0.817857    0.850428         0.935029  ...   \n",
       "9            0.881994        0.821429    0.850153         0.933530  ...   \n",
       "15           0.766541        0.719643    0.739608         0.820233  ...   \n",
       "\n",
       "    recall_cv_std  f1_cv_std  roc_auc_cv_std  kappa_cv_std  accuracy_test  \\\n",
       "1        0.031237   0.019523        0.009301      0.037201          0.745   \n",
       "0        0.036857   0.018545        0.009784      0.032242          0.740   \n",
       "2        0.026245   0.013489        0.008891      0.025505          0.725   \n",
       "3        0.025877   0.014522        0.008134      0.026486          0.720   \n",
       "10       0.024614   0.014120        0.014539      0.026845          0.715   \n",
       "11       0.024223   0.012778        0.014631      0.024354          0.715   \n",
       "14       0.094929   0.067031        0.038358      0.118934          0.720   \n",
       "8        0.028571   0.019669        0.013822      0.036770          0.700   \n",
       "9        0.029342   0.018125        0.013851      0.033216          0.695   \n",
       "15       0.093576   0.066939        0.038342      0.119443          0.715   \n",
       "\n",
       "    precision_test  recall_test   f1_test  roc_auc_test  kappa_test  \n",
       "1         0.798658     0.850000  0.823529      0.794286    0.365672  \n",
       "0         0.823529     0.800000  0.811594      0.787262    0.392523  \n",
       "2         0.793103     0.821429  0.807018      0.785119    0.329268  \n",
       "3         0.783784     0.828571  0.805556      0.783571    0.306931  \n",
       "10        0.790210     0.807143  0.798587      0.722857    0.311594  \n",
       "11        0.790210     0.807143  0.798587      0.725119    0.311594  \n",
       "14        0.833333     0.750000  0.789474      0.774762    0.375000  \n",
       "8         0.789855     0.778571  0.784173      0.741310    0.292453  \n",
       "9         0.780142     0.785714  0.782918      0.744405    0.270335  \n",
       "15        0.848739     0.721429  0.779923      0.777738    0.383117  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores por cenário:\n",
      "normal => {'algorithm': 'rf', 'optimizer': 'random', 'f1_test': np.float64(0.8235294117647058), 'roc_auc_test': np.float64(0.7942857142857143), 'best_params': {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 237}, 'n_runs': 16, 'n_failures': 0, 'failures': []}\n",
      "pca_3 => {'algorithm': 'rf', 'optimizer': 'grid', 'f1_test': np.float64(0.7730496453900709), 'roc_auc_test': np.float64(0.6672619047619048), 'best_params': {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}, 'n_runs': 16, 'n_failures': 0, 'failures': []}\n"
     ]
    }
   ],
   "source": [
    "experiment_results = pd.DataFrame(experiment_records)\n",
    "print(\"\\nResumo (top 10 por F1 em teste):\")\n",
    "if not experiment_results.empty:\n",
    "    display(experiment_results.sort_values(['scenario', 'f1_test'], ascending=[True, False]).head(10))\n",
    "\n",
    "print('\\nMelhores por cenário:')\n",
    "for scen, info in best_result_per_scenario.items():\n",
    "    print(scen, '=>', info)\n",
    "\n",
    "experiment_results.to_csv('resultados_experimentos.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
