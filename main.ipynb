{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a3a9ec",
   "metadata": {},
   "source": [
    "# Carregamento da Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ed01c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ucimlrepo in /home/alef/.local/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /home/alef/.local/lib/python3.10/site-packages (from ucimlrepo) (2025.11.12)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/alef/.local/lib/python3.10/site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: ucimlrepo in /home/alef/.local/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /home/alef/.local/lib/python3.10/site-packages (from ucimlrepo) (2025.11.12)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/alef/.local/lib/python3.10/site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.0.0->ucimlrepo) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.0.0->ucimlrepo) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alef/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ed1b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "statlog_german_credit_data = fetch_ucirepo(id=144) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_german_credit_data.data.features \n",
    "y = statlog_german_credit_data.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada4383",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c701c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Reamostragem (classes desbalanceadas)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Validação e busca de hiperparâmetros\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    ")\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "# Otimizadores\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real as SKOReal, Integer as SKOInteger, Categorical as SKOCategorical\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Continuous as GAContinuous, Integer as GAInteger, Categorical as GACategorical\n",
    "\n",
    "# Utilidades\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af70e8",
   "metadata": {},
   "source": [
    "# Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423cf620",
   "metadata": {},
   "source": [
    "## Juntar as features e o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9117e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X, y], axis=1)\n",
    "data.columns = list(X.columns) + ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d4bc3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Attribute1   1000 non-null   object\n",
      " 1   Attribute2   1000 non-null   int64 \n",
      " 2   Attribute3   1000 non-null   object\n",
      " 3   Attribute4   1000 non-null   object\n",
      " 4   Attribute5   1000 non-null   int64 \n",
      " 5   Attribute6   1000 non-null   object\n",
      " 6   Attribute7   1000 non-null   object\n",
      " 7   Attribute8   1000 non-null   int64 \n",
      " 8   Attribute9   1000 non-null   object\n",
      " 9   Attribute10  1000 non-null   object\n",
      " 10  Attribute11  1000 non-null   int64 \n",
      " 11  Attribute12  1000 non-null   object\n",
      " 12  Attribute13  1000 non-null   int64 \n",
      " 13  Attribute14  1000 non-null   object\n",
      " 14  Attribute15  1000 non-null   object\n",
      " 15  Attribute16  1000 non-null   int64 \n",
      " 16  Attribute17  1000 non-null   object\n",
      " 17  Attribute18  1000 non-null   int64 \n",
      " 18  Attribute19  1000 non-null   object\n",
      " 19  Attribute20  1000 non-null   object\n",
      " 20  target       1000 non-null   int64 \n",
      "dtypes: int64(8), object(13)\n",
      "memory usage: 164.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1ac8f",
   "metadata": {},
   "source": [
    "## Remoção de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00f36db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute11</th>\n",
       "      <th>Attribute13</th>\n",
       "      <th>Attribute16</th>\n",
       "      <th>Attribute18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.307000</td>\n",
       "      <td>3051.101000</td>\n",
       "      <td>2.973000</td>\n",
       "      <td>2.845000</td>\n",
       "      <td>35.453500</td>\n",
       "      <td>1.404000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.615151</td>\n",
       "      <td>2187.140403</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>11.106324</td>\n",
       "      <td>0.565335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2319.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3972.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>7882.375000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Attribute2   Attribute5   Attribute8  Attribute11  Attribute13  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     20.307000  3051.101000     2.973000     2.845000    35.453500   \n",
       "std      10.615151  2187.140403     1.118715     1.103718    11.106324   \n",
       "min       4.000000   250.000000     1.000000     1.000000    19.000000   \n",
       "25%      12.000000  1365.500000     2.000000     2.000000    27.000000   \n",
       "50%      18.000000  2319.500000     3.000000     3.000000    33.000000   \n",
       "75%      24.000000  3972.250000     4.000000     4.000000    42.000000   \n",
       "max      42.000000  7882.375000     4.000000     4.000000    64.500000   \n",
       "\n",
       "       Attribute16  Attribute18  \n",
       "count  1000.000000       1000.0  \n",
       "mean      1.404000          1.0  \n",
       "std       0.565335          0.0  \n",
       "min       1.000000          1.0  \n",
       "25%       1.000000          1.0  \n",
       "50%       1.000000          1.0  \n",
       "75%       2.000000          1.0  \n",
       "max       3.500000          1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != 'target']\n",
    "\n",
    "# IQR capping  \n",
    "def iqr_cap(series, factor=1.5):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - factor * iqr\n",
    "    upper = q3 + factor * iqr\n",
    "    return series.clip(lower, upper)\n",
    "\n",
    "# Aplicar capping aos numéricos\n",
    "for col in numeric_cols:\n",
    "    data[col] = iqr_cap(data[col])\n",
    "\n",
    "data[numeric_cols].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1c06c",
   "metadata": {},
   "source": [
    "## Separação Entre Features e Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fa447c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75082fd",
   "metadata": {},
   "source": [
    "## Separar Features Numericas e Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "980c00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X.select_dtypes(include=np.number).columns\n",
    "categorical_features = X.select_dtypes(exclude=np.number).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b62db",
   "metadata": {},
   "source": [
    "## Pipeline de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2471f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numéricas: imputar valores ausentes com a mediana e escalar\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# categóricas: imputar valores ausentes com o valor mais frequente e aplicar One-Hot Encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f5ada",
   "metadata": {},
   "source": [
    "## Processador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b78889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um pré-processador usando ColumnTransformer para aplicar transformações diferentes a diferentes colunas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # Manter outras colunas não especificadas, se houver\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05163c5a",
   "metadata": {},
   "source": [
    "### Aplicando as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56ddbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876ff3b",
   "metadata": {},
   "source": [
    "## Convertendo Rótulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24017660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original usa 1 = Good, 2 = Bad. Converter 2 para 0 para ter classes 0 e 1.\n",
    "y_processed = y.values.ravel()\n",
    "y_processed = np.where(y_processed == 2, 0, y_processed) # 1 (Good credit), 0 (Bad credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7cd1f",
   "metadata": {},
   "source": [
    "## Split Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54a6feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_processed, test_size=0.2, random_state=RANDOM_STATE, stratify=y_processed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7fe6d",
   "metadata": {},
   "source": [
    "## Dados Sinteticos (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a954119",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1069d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': (1120, 61), 'pca_3': (1120, 3)}\n"
     ]
    }
   ],
   "source": [
    "## Cenários de Classificação (Normal vs PCA 3 componentes)\n",
    "from scipy import sparse\n",
    "\n",
    "# Garantir densidade para algoritmos que exigem matriz densa\n",
    "def to_dense(X):\n",
    "    return X.toarray() if sparse.issparse(X) else X\n",
    "\n",
    "X_train_resampled = X_resampled  # resultado do SMOTE\n",
    "X_test_original = X_test         # teste sem oversampling\n",
    "\n",
    "X_train_resampled_dense = to_dense(X_train_resampled)\n",
    "X_test_dense = to_dense(X_test_original)\n",
    "\n",
    "# Cenário PCA (3 componentes)\n",
    "pca = PCA(n_components=3, random_state=RANDOM_STATE)\n",
    "X_train_pca = pca.fit_transform(X_train_resampled_dense)\n",
    "X_test_pca = pca.transform(X_test_dense)\n",
    "\n",
    "scenarios = {\n",
    "    'normal': (X_train_resampled_dense, X_test_dense),\n",
    "    'pca_3': (X_train_pca, X_test_pca)\n",
    "}\n",
    "print({k: v[0].shape for k, v in scenarios.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cad6685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espaços definidos: OK\n"
     ]
    }
   ],
   "source": [
    "## Espaços de Hiperparâmetros (Grid, Random, Bayes, Genética)\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Estimadores base\n",
    "estimators = {\n",
    "    'rf': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'svm': SVC(probability=True, random_state=RANDOM_STATE),\n",
    "    'mlp': MLPClassifier(max_iter=300, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# Grid (pequeno para demonstração)\n",
    "param_grid = {\n",
    "    'rf': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': [5, 11, 17],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': [0.5, 1, 5],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(50,), (100,)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Random distributions\n",
    "param_dist = {\n",
    "    'rf': {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': [None] + list(range(5, 16, 5)),\n",
    "        'min_samples_split': randint(2, 10)\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': randint(3, 25),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': randint(1, 3)\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': uniform(0.1, 10),\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(randint.rvs(40, 120),)],\n",
    "        'alpha': uniform(1e-5, 1e-2),\n",
    "        'learning_rate_init': uniform(1e-4, 1e-2)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Bayes search spaces\n",
    "bayes_spaces = {\n",
    "    'rf': {\n",
    "        'n_estimators': SKOInteger(50, 300),\n",
    "        'max_depth': SKOCategorical([None, 5, 10, 15]),\n",
    "        'min_samples_split': SKOInteger(2, 10)\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': SKOInteger(3, 25),\n",
    "        'weights': SKOCategorical(['uniform', 'distance']),\n",
    "        'p': SKOInteger(1, 2)\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': SKOReal(0.1, 10.0, prior='log-uniform'),\n",
    "        'gamma': SKOCategorical(['scale', 'auto']),\n",
    "        'kernel': SKOCategorical(['rbf', 'linear'])\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': SKOCategorical([(50,), (100,), (150,)]),\n",
    "        'alpha': SKOReal(1e-5, 1e-2, prior='log-uniform'),\n",
    "        'learning_rate_init': SKOReal(1e-4, 1e-2, prior='log-uniform')\n",
    "    }\n",
    "}\n",
    "\n",
    "# GA search spaces\n",
    "ga_spaces = {\n",
    "    'rf': {\n",
    "        'n_estimators': GAInteger(50, 300),\n",
    "        'max_depth': GACategorical([None, 5, 10, 15]),\n",
    "        'min_samples_split': GAInteger(2, 10)\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': GAInteger(3, 25),\n",
    "        'weights': GACategorical(['uniform', 'distance']),\n",
    "        'p': GAInteger(1, 2)\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': GAContinuous(0.1, 10.0),\n",
    "        'gamma': GACategorical(['scale', 'auto']),\n",
    "        'kernel': GACategorical(['rbf', 'linear'])\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': GACategorical([(50,), (100,), (150,)]),\n",
    "        'alpha': GAContinuous(1e-5, 1e-2),\n",
    "        'learning_rate_init': GAContinuous(1e-4, 1e-2)\n",
    "    }\n",
    "}\n",
    "print('Espaços definidos: OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ec2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funções definidas: OK\n"
     ]
    }
   ],
   "source": [
    "## Funções de Otimização e Métricas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'kappa': make_scorer(cohen_kappa_score)\n",
    "}\n",
    "\n",
    "import time\n",
    "\n",
    "def fit_search(search_obj, X, y):\n",
    "    start = time.time()\n",
    "    search_obj.fit(X, y)\n",
    "    return search_obj, time.time() - start\n",
    "\n",
    "def build_search(alg_key, search_type):\n",
    "    est = estimators[alg_key]\n",
    "    if search_type == 'grid':\n",
    "        return GridSearchCV(est, param_grid[alg_key], cv=cv, scoring='f1', n_jobs=-1, refit=True)\n",
    "    if search_type == 'random':\n",
    "        return RandomizedSearchCV(est, param_distributions=param_dist[alg_key], cv=cv, scoring='f1', n_iter=15, random_state=RANDOM_STATE, n_jobs=-1, refit=True)\n",
    "    if search_type == 'bayes':\n",
    "        return BayesSearchCV(est, bayes_spaces[alg_key], cv=cv, scoring='f1', n_iter=25, random_state=RANDOM_STATE, n_jobs=-1, refit=True)\n",
    "    if search_type == 'genetic':\n",
    "        return GASearchCV(estimator=est, cv=cv, scoring='f1', population_size=15, generations=10, tournament_size=3,\n",
    "                          n_jobs=-1, verbose=False, param_grid=ga_spaces[alg_key])\n",
    "    raise ValueError('Tipo de busca inválido')\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def evaluate_best(best_estimator, X_train, y_train, X_test, y_test):\n",
    "    # CV detalhado nas métricas\n",
    "    cv_results = cross_validate(best_estimator, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "    summary_cv = {f'{m}_cv_mean': np.mean(cv_results[f'test_{m}']) for m in ['accuracy','precision','recall','f1','roc_auc','kappa']}\n",
    "    summary_cv.update({f'{m}_cv_std': np.std(cv_results[f'test_{m}']) for m in ['accuracy','precision','recall','f1','roc_auc','kappa']})\n",
    "\n",
    "    # Test set\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "    if hasattr(best_estimator, 'predict_proba'):\n",
    "        y_proba = best_estimator.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        # fallback para decision_function se existir\n",
    "        if hasattr(best_estimator, 'decision_function'):\n",
    "            from sklearn.preprocessing import MinMaxScaler\n",
    "            dec = best_estimator.decision_function(X_test).reshape(-1,1)\n",
    "            y_proba = MinMaxScaler().fit_transform(dec).ravel()\n",
    "        else:\n",
    "            y_proba = y_pred  # aproximação\n",
    "\n",
    "    test_metrics = {\n",
    "        'accuracy_test': accuracy_score(y_test, y_pred),\n",
    "        'precision_test': precision_score(y_test, y_pred),\n",
    "        'recall_test': recall_score(y_test, y_pred),\n",
    "        'f1_test': f1_score(y_test, y_pred),\n",
    "        'roc_auc_test': roc_auc_score(y_test, y_proba),\n",
    "        'kappa_test': cohen_kappa_score(y_test, y_pred)\n",
    "    }\n",
    "    return {**summary_cv, **test_metrics}\n",
    "\n",
    "print('Funções definidas: OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daf6716",
   "metadata": {},
   "source": [
    "## Loop de Experimentos (Cenários x Modelos x Otimizadores)\n",
    "\n",
    "Este bloco executa as buscas de hiperparâmetros (Grid, Random, Bayes, Genética) para RF, KNN, SVM e MLP em dois cenários: normal e PCA(3). Coleta métricas (médias e desvios no CV e desempenho em teste) e tempo de execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c7661ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cenário: normal ===\n",
      " - RF via grid\n",
      " - RF via random\n",
      " - RF via random\n",
      " - RF via bayes\n",
      " - RF via bayes\n",
      " - RF via genetic\n",
      " - RF via genetic\n",
      " - KNN via grid\n",
      " - KNN via random\n",
      " - KNN via grid\n",
      " - KNN via random\n",
      " - KNN via bayes\n",
      " - KNN via bayes\n",
      " - KNN via genetic\n",
      " - KNN via genetic\n",
      " - SVM via grid\n",
      " - SVM via grid\n",
      " - SVM via random\n",
      " - SVM via random\n",
      " - SVM via bayes\n",
      " - SVM via bayes\n",
      " - SVM via genetic\n",
      " - SVM via genetic\n",
      " - MLP via grid\n",
      " - MLP via grid\n",
      " - MLP via random\n",
      " - MLP via random\n",
      " - MLP via bayes\n",
      " - MLP via bayes\n",
      "   ! Falhou: Not all points are within the bounds of the space.\n",
      " - MLP via genetic\n",
      "   ! Falhou: Not all points are within the bounds of the space.\n",
      " - MLP via genetic\n",
      "\n",
      "=== Cenário: pca_3 ===\n",
      " - RF via grid\n",
      "\n",
      "=== Cenário: pca_3 ===\n",
      " - RF via grid\n",
      " - RF via random\n",
      " - RF via random\n",
      " - RF via bayes\n",
      " - RF via bayes\n",
      " - RF via genetic\n",
      " - RF via genetic\n",
      " - KNN via grid\n",
      " - KNN via random\n",
      " - KNN via grid\n",
      " - KNN via random\n",
      " - KNN via bayes\n",
      " - KNN via bayes\n",
      " - KNN via genetic\n",
      " - KNN via genetic\n",
      " - SVM via grid\n",
      " - SVM via grid\n",
      " - SVM via random\n",
      " - SVM via random\n",
      " - SVM via bayes\n",
      " - SVM via bayes\n",
      " - SVM via genetic\n",
      " - SVM via genetic\n",
      " - MLP via grid\n",
      " - MLP via grid\n",
      " - MLP via random\n",
      " - MLP via random\n",
      " - MLP via bayes\n",
      " - MLP via bayes\n",
      "   ! Falhou: Not all points are within the bounds of the space.\n",
      " - MLP via genetic\n",
      "   ! Falhou: Not all points are within the bounds of the space.\n",
      " - MLP via genetic\n",
      "\n",
      "Resumo (top 10 por F1 em teste):\n",
      "\n",
      "Resumo (top 10 por F1 em teste):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>best_params</th>\n",
       "      <th>accuracy_cv_mean</th>\n",
       "      <th>precision_cv_mean</th>\n",
       "      <th>recall_cv_mean</th>\n",
       "      <th>f1_cv_mean</th>\n",
       "      <th>roc_auc_cv_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_cv_std</th>\n",
       "      <th>f1_cv_std</th>\n",
       "      <th>roc_auc_cv_std</th>\n",
       "      <th>kappa_cv_std</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>roc_auc_test</th>\n",
       "      <th>kappa_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>rf</td>\n",
       "      <td>random</td>\n",
       "      <td>8.857357</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_e...</td>\n",
       "      <td>0.849107</td>\n",
       "      <td>0.834394</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.852226</td>\n",
       "      <td>0.925446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031237</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.009301</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.798658</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.365672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>rf</td>\n",
       "      <td>grid</td>\n",
       "      <td>5.263286</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.837010</td>\n",
       "      <td>0.860714</td>\n",
       "      <td>0.848255</td>\n",
       "      <td>0.922816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036857</td>\n",
       "      <td>0.018545</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.032242</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.787262</td>\n",
       "      <td>0.392523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>rf</td>\n",
       "      <td>genetic</td>\n",
       "      <td>154.132376</td>\n",
       "      <td>{'n_estimators': 282, 'max_depth': None, 'min_...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839074</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.860730</td>\n",
       "      <td>0.928300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025877</td>\n",
       "      <td>0.015051</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.785235</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.809689</td>\n",
       "      <td>0.785476</td>\n",
       "      <td>0.315920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>rf</td>\n",
       "      <td>bayes</td>\n",
       "      <td>54.984208</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 3, 'n_e...</td>\n",
       "      <td>0.851786</td>\n",
       "      <td>0.834242</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.855536</td>\n",
       "      <td>0.927583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.025505</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.785119</td>\n",
       "      <td>0.329268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>normal</td>\n",
       "      <td>svm</td>\n",
       "      <td>bayes</td>\n",
       "      <td>20.956353</td>\n",
       "      <td>{'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.896727</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.852024</td>\n",
       "      <td>0.941486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024614</td>\n",
       "      <td>0.014120</td>\n",
       "      <td>0.014539</td>\n",
       "      <td>0.026845</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.798587</td>\n",
       "      <td>0.722857</td>\n",
       "      <td>0.311594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>normal</td>\n",
       "      <td>svm</td>\n",
       "      <td>genetic</td>\n",
       "      <td>75.777912</td>\n",
       "      <td>{'C': 9.542163751882395, 'gamma': 'scale', 'ke...</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.895206</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.852323</td>\n",
       "      <td>0.941231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>0.014598</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.798587</td>\n",
       "      <td>0.724524</td>\n",
       "      <td>0.311594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>normal</td>\n",
       "      <td>mlp</td>\n",
       "      <td>genetic</td>\n",
       "      <td>196.137040</td>\n",
       "      <td>{'hidden_layer_sizes': (50,), 'alpha': 0.00473...</td>\n",
       "      <td>0.859821</td>\n",
       "      <td>0.893856</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.853468</td>\n",
       "      <td>0.921971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034626</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>0.017263</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.802920</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.794224</td>\n",
       "      <td>0.724762</td>\n",
       "      <td>0.330986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>normal</td>\n",
       "      <td>mlp</td>\n",
       "      <td>grid</td>\n",
       "      <td>16.058830</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.851786</td>\n",
       "      <td>0.884363</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.845104</td>\n",
       "      <td>0.912691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>0.021643</td>\n",
       "      <td>0.021536</td>\n",
       "      <td>0.038049</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.791367</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.788530</td>\n",
       "      <td>0.704286</td>\n",
       "      <td>0.300948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>normal</td>\n",
       "      <td>svm</td>\n",
       "      <td>grid</td>\n",
       "      <td>5.072419</td>\n",
       "      <td>{'C': 5, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.886675</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.850428</td>\n",
       "      <td>0.935029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.784173</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.292453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normal</td>\n",
       "      <td>svm</td>\n",
       "      <td>random</td>\n",
       "      <td>7.492666</td>\n",
       "      <td>{'C': 4.419450186421157, 'gamma': 'scale', 'ke...</td>\n",
       "      <td>0.855357</td>\n",
       "      <td>0.881994</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.850153</td>\n",
       "      <td>0.933530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029342</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>0.013851</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.780142</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.744405</td>\n",
       "      <td>0.270335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scenario algorithm optimizer    time_sec  \\\n",
       "1    normal        rf    random    8.857357   \n",
       "0    normal        rf      grid    5.263286   \n",
       "3    normal        rf   genetic  154.132376   \n",
       "2    normal        rf     bayes   54.984208   \n",
       "10   normal       svm     bayes   20.956353   \n",
       "11   normal       svm   genetic   75.777912   \n",
       "14   normal       mlp   genetic  196.137040   \n",
       "12   normal       mlp      grid   16.058830   \n",
       "8    normal       svm      grid    5.072419   \n",
       "9    normal       svm    random    7.492666   \n",
       "\n",
       "                                          best_params  accuracy_cv_mean  \\\n",
       "1   {'max_depth': 15, 'min_samples_split': 5, 'n_e...          0.849107   \n",
       "0   {'max_depth': 10, 'min_samples_split': 2, 'n_e...          0.846429   \n",
       "3   {'n_estimators': 282, 'max_depth': None, 'min_...          0.857143   \n",
       "2   {'max_depth': 15, 'min_samples_split': 3, 'n_e...          0.851786   \n",
       "10     {'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}          0.858929   \n",
       "11  {'C': 9.542163751882395, 'gamma': 'scale', 'ke...          0.858929   \n",
       "14  {'hidden_layer_sizes': (50,), 'alpha': 0.00473...          0.859821   \n",
       "12  {'activation': 'relu', 'alpha': 0.001, 'hidden...          0.851786   \n",
       "8         {'C': 5, 'gamma': 'scale', 'kernel': 'rbf'}          0.856250   \n",
       "9   {'C': 4.419450186421157, 'gamma': 'scale', 'ke...          0.855357   \n",
       "\n",
       "    precision_cv_mean  recall_cv_mean  f1_cv_mean  roc_auc_cv_mean  ...  \\\n",
       "1            0.834394        0.871429    0.852226         0.925446  ...   \n",
       "0            0.837010        0.860714    0.848255         0.922816  ...   \n",
       "3            0.839074        0.883929    0.860730         0.928300  ...   \n",
       "2            0.834242        0.878571    0.855536         0.927583  ...   \n",
       "10           0.896727        0.812500    0.852024         0.941486  ...   \n",
       "11           0.895206        0.814286    0.852323         0.941231  ...   \n",
       "14           0.893856        0.817857    0.853468         0.921971  ...   \n",
       "12           0.884363        0.810714    0.845104         0.912691  ...   \n",
       "8            0.886675        0.817857    0.850428         0.935029  ...   \n",
       "9            0.881994        0.821429    0.850153         0.933530  ...   \n",
       "\n",
       "    recall_cv_std  f1_cv_std  roc_auc_cv_std  kappa_cv_std  accuracy_test  \\\n",
       "1        0.031237   0.019523        0.009301      0.037201          0.745   \n",
       "0        0.036857   0.018545        0.009784      0.032242          0.740   \n",
       "3        0.025877   0.015051        0.007904      0.028235          0.725   \n",
       "2        0.026245   0.013489        0.008891      0.025505          0.725   \n",
       "10       0.024614   0.014120        0.014539      0.026845          0.715   \n",
       "11       0.023555   0.013597        0.014598      0.026245          0.715   \n",
       "14       0.034626   0.019787        0.017263      0.035084          0.715   \n",
       "12       0.039286   0.021643        0.021536      0.038049          0.705   \n",
       "8        0.028571   0.019669        0.013822      0.036770          0.700   \n",
       "9        0.029342   0.018125        0.013851      0.033216          0.695   \n",
       "\n",
       "    precision_test  recall_test   f1_test  roc_auc_test  kappa_test  \n",
       "1         0.798658     0.850000  0.823529      0.794286    0.365672  \n",
       "0         0.823529     0.800000  0.811594      0.787262    0.392523  \n",
       "3         0.785235     0.835714  0.809689      0.785476    0.315920  \n",
       "2         0.793103     0.821429  0.807018      0.785119    0.329268  \n",
       "10        0.790210     0.807143  0.798587      0.722857    0.311594  \n",
       "11        0.790210     0.807143  0.798587      0.724524    0.311594  \n",
       "14        0.802920     0.785714  0.794224      0.724762    0.330986  \n",
       "12        0.791367     0.785714  0.788530      0.704286    0.300948  \n",
       "8         0.789855     0.778571  0.784173      0.741310    0.292453  \n",
       "9         0.780142     0.785714  0.782918      0.744405    0.270335  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores por cenário:\n",
      "normal => {'algorithm': 'rf', 'optimizer': 'random', 'f1_test': np.float64(0.8235294117647058), 'roc_auc_test': np.float64(0.7942857142857143), 'best_params': {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 237}}\n",
      "pca_3 => {'algorithm': 'rf', 'optimizer': 'grid', 'f1_test': np.float64(0.7730496453900709), 'roc_auc_test': np.float64(0.6672619047619048), 'best_params': {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}}\n"
     ]
    }
   ],
   "source": [
    "# Execução dos Experimentos\n",
    "\n",
    "results = []\n",
    "best_by_scenario = {}\n",
    "\n",
    "optimizers = ['grid', 'random', 'bayes', 'genetic']\n",
    "\n",
    "for scen_name, (Xtr, Xte) in scenarios.items():\n",
    "    print(f\"\\n=== Cenário: {scen_name} ===\")\n",
    "    # y para treino (após SMOTE) e teste (original)\n",
    "    ytr = y_resampled\n",
    "    yte = y_test\n",
    "\n",
    "    scen_records = []\n",
    "\n",
    "    for alg_key in estimators.keys():\n",
    "        for opt in optimizers:\n",
    "            print(f\" - {alg_key.upper()} via {opt}\")\n",
    "            try:\n",
    "                search = build_search(alg_key, opt)\n",
    "                fitted, elapsed = fit_search(search, Xtr, ytr)\n",
    "                best_est = fitted.best_estimator_\n",
    "                metrics = evaluate_best(best_est, Xtr, ytr, Xte, yte)\n",
    "\n",
    "                record = {\n",
    "                    'scenario': scen_name,\n",
    "                    'algorithm': alg_key,\n",
    "                    'optimizer': opt,\n",
    "                    'time_sec': elapsed,\n",
    "                    'best_params': fitted.best_params_,\n",
    "                }\n",
    "                record.update(metrics)\n",
    "                results.append(record)\n",
    "                scen_records.append(record)\n",
    "            except Exception as e:\n",
    "                print(f\"   ! Falhou: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Selecionar melhor por F1 em teste neste cenário\n",
    "    if scen_records:\n",
    "        scen_df = pd.DataFrame(scen_records)\n",
    "        top = scen_df.sort_values('f1_test', ascending=False).iloc[0]\n",
    "        best_by_scenario[scen_name] = {\n",
    "            'algorithm': top['algorithm'],\n",
    "            'optimizer': top['optimizer'],\n",
    "            'f1_test': top['f1_test'],\n",
    "            'roc_auc_test': top['roc_auc_test'],\n",
    "            'best_params': top['best_params'],\n",
    "        }\n",
    "\n",
    "# Consolidar resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nResumo (top 10 por F1 em teste):\")\n",
    "if not results_df.empty:\n",
    "    display(results_df.sort_values(['scenario', 'f1_test'], ascending=[True, False]).head(10))\n",
    "\n",
    "print('\\nMelhores por cenário:')\n",
    "for scen, info in best_by_scenario.items():\n",
    "    print(scen, '=>', info)\n",
    "\n",
    "# Opcional: salvar em CSV\n",
    "results_df.to_csv('resultados_experimentos.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
